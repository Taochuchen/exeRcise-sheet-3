---
title: "Exercise #3"
subtitle: "Fortgeschrittene Statistische Software für NF"
author: "Chuchen Tao (12523759)."
date: "`r Sys.Date()`"
output: distill::distill_article
---

## General Remarks

-   You can submit your solutions in teams of up to 3 students.
-   Include all your team-member's names and student numbers
    (Martrikelnummern) in the `authors` field.
-   Please use the exercise template document to work on and submit your
    results.
-   Use a level 2 heading for each new exercise and answer each subtask
    next to it's bullet point or use a new level 3 heading if you want.
-   Always render the R code for your solutions and make sure to include
    the resulting data in your rendered document.
    -   Make sure to not print more than 10 rows of data (unless
        specifically instructed to).
-   Always submit both the rendered document(s) as well as your source
    Rmarkdown document. Submit the files separately on moodle, **not**
    as a zip archive.

## Exercise 1: Initializing git (4 Points)

For this whole exercise sheet we will be tracking all our changes to it
in git.

a)  Start by initializing a new R project with git support, called
    `2024-exeRcise-sheet-3`. If you forgot how to do this, you can
    follow this
    [guide](https://malikaihle.github.io/Introduction-RStudio-Git-GitHub/rstudio_project.html).
b)  Commit the files generated by Rstudio.
c)  For all of the following tasks in this exercise sheet we ask you to
    always commit your changes after finishing each subtask e.g. create
    a commit after task *1d*, *1e* etc.

> Note: This applies only to answers that have text or code as their
> answer. If you complete tasks in a different order or forget to commit
> one, this is no problem. If you change your answers you can just
> create multiple commits to track the changes.

d)  Name 2 strengths and 2 weaknesses of git. (Don't forget to create a
    commit after this answer, see *1c*)
    
    Strengths:

    Works Offline: You can use Git without an internet connection. Each person 
                   has a full copy of the project history on their computer, so 
                   you can work anywhere, anytime.
    Easy Branching: You can create separate branches to work on different 
                   features or fixes without affecting the main project. Merging
                   these branches back is also very efficient.
    
    Weaknesses:

    Hard to Learn: Git has many commands and options that can be confusing for 
                   beginners. It can take time to understand how to use it 
                   effectively.
    Risk of Mistakes: Some Git commands can permanently delete your work or 
                      overwrite changes if used incorrectly, which can be 
                      frustrating and hard to fix.
e)  Knit this exercise sheet. Some new files will automatically be
    generated when knitting the sheet e.g. the HTML page. Ignore these
    files, as we only want to track the source files themselves.

## Exercise 2: Putting your Repository on GitHub (3.5 Points)

For this task you will upload your solution to GitHub.

a)  Create a new repository on GitHub in your account named
    `exeRcise-sheet-3`. Make sure you create a **public repository** so
    we are able to see it for grading. Add the link to the repository
    below:
    
    https://github.com/Taochuchen/exeRcise-sheet-3.git
    
b)  Push your code to this new repository by copying and executing the
    snippet on github listed under
    `…or push an existing repository from the command line`.
c)  Regularly push your latest changes to GitHub again and especially do
    so when you are finished with this sheet.

## Exercise 3: Baby-Names in Munich (3.5 Points)

Download the latest open datasets on given names ("Vornamen") from the
open data repository of the city of Munich for the years `2023` and
`2022`.

Link: <https://opendata.muenchen.de/dataset/vornamen-von-neugeborenen>

a)  Download the data for both years and track it in git. For small
    datasets like these adding them to git is not a problem.

b)  Load the data for both years into R. Check the type of the count
    variable ("Anzahl") and look into the data to determine why it is
    not numeric? Fix the problem in an appropriate manner, it is OK if
    some of the counts are inaccurate because of this. Explain your
    solution and the repercussions.
    
    ```{r}
    library(readr)
    library(dplyr)
    library(knitr)
    data_2022 <- read_csv("data/open_data_portal_2022.csv")
    data_2023 <- read_csv("data/vornamen-muenchen-2023.csv")
    str(data_2022)
    str(data_2023)
    data_2022 <- data_2022 %>%
      mutate(Anzahl = as.numeric(Anzahl))
    data_2023 <- data_2023 %>%
      mutate(Anzahl = as.numeric(Anzahl))
    ```
   
    Solution:Use the as.numeric function to convert the Anzahl column to 
             numeric. Any non-numeric values will be turned into NA. Ignore NA 
             values during calculations to ensure accurate numeric data 
             processing.
    Repercussions: Non-numeric values will become NA, and these entries will be 
                   ignored, leading to slight inaccuracies in the total counts.
                   Converting all counts to numeric makes further analysis 
                   easier and avoids complications from mixed data types.



c)  Calculate the total number of babies born in Munich in 2022
    and 2023. Which year had the bigger baby-boom?
    ```{r}
    total_2022 <- sum(data_2022$Anzahl, na.rm = TRUE)
    total_2023 <- sum(data_2023$Anzahl, na.rm = TRUE)
    ```

    2022 had the bigger baby-boom.
    
d)  Add a new column `year` to both datasets which holds the correct
    year for each.
    
    ```{r}
    data_2022 <- data_2022 %>%
      mutate(year = 2022)

    data_2023 <- data_2023 %>%
      mutate(year = 2023)
    ```
    

e)  Combine both datasets into one using `bind_rows()`.

```{r}
combined_data <- bind_rows(data_2022, data_2023)
```

f)  Combine the counts for same names to determine the most popular
    names across both years. Print out the top 10 names in a nicely
    formatted table for both years. Include a table caption.
```{r}
top_names <- combined_data %>%
  group_by(Vorname) %>%
  summarise(total_count = sum(Anzahl, na.rm = TRUE)) %>%
  arrange(desc(total_count)) %>%
  slice_head(n = 10)

kable(top_names, caption = "Top 10 Most Popular Baby Names in Munich (2022 and 2023)")
```
## Exercise 4: Open Analysis (4 points)

This exercise is a bit more open-ended. You can choose any dataset from
[Our World in Data](https://ourworldindata.org/) and analyze it, while
determining the research question yourself.

a)  Go to <https://github.com/owid/owid-datasets/tree/master/datasets>
    and choose a dataset that interests you. You can have a look at
    <https://ourworldindata.org/> to gather some inspiration.
b)  Download the dataset and track it in git.
c)  Put the name / title of the dataset and a link to it below.

-   Dataset Name: Daily supply of calories per person (OWID based on UN FAO & 
                  historical sources)
-   Link: <https://github.com/owid/owid-datasets/blob/master/datasets/Daily%20supply%20of%20calories%20per%20person%20(OWID%20based%20on%20UN%20FAO%20%26%20historical%20sources)/Daily%20supply%20of%20calories%20per%20person%20(OWID%20based%20on%20UN%20FAO%20%26%20historical%20sources).csv>

d)  Come up with a (research) question you want to answer with the data
    and briefly explain why you believe this is an interesting question
    within one sentence. It should be a question that can be answered
    with the dataset and using R.
    
    Question:
    How has the average daily calorie supply per person changed globally over 
    the past few decades？
    
    Why interesting:
    This question is interesting because it helps us see if people are getting 
    enough food over time.
    
e)  Use R to answer your chosen question.

```{r}
library(readr)
library(dplyr)
library(ggplot2)
calories_data <- read_csv("data/Daily supply of calories per person (OWID based on UN FAO & historical sources).csv")
str(calories_data)
calories_data <- calories_data %>%
  select(Entity, Year, Calories = `Daily caloric supply (OWID based on UN FAO & historical sources)`)

calories_data <- calories_data %>%
  filter(!is.na(Calories))

average_calories <- calories_data %>%
  group_by(Year) %>%
  summarise(avg_calories = mean(Calories, na.rm = TRUE))
```
f)  Create a meaningful plot / figure with the dataset. Make sure to
    provide a figure caption (via the chunk options / Rmarkdown) and
    correctly label the figure.
```{r}
ggplot(average_calories, aes(x = Year, y = avg_calories)) +
  geom_line(color = "blue") +
  labs(title = "Average Daily Calories per Capita (1960 - Present)",
       x = "Year",
       y = "Daily Calories per Capita",
       caption = "Data source: Our World in Data") +
  theme_minimal()
```
## Final Note

Make sure to push all your commits and changes to GitHub before
submittining the exercise sheet.
